Yes, you can use RAGFlow with LangChain by integrating RAGFlow as an external retriever/context provider. The recommended approach is to use RAGFlow’s REST API or Python SDK to fetch relevant context chunks from your knowledge base, then pass those results into LangChain for orchestration and LLM calls. There’s no dedicated LangChain integration, but the API/SDK pattern is straightforward: call RAGFlow’s /retrieval endpoint (or use the retrieve method in the Python SDK) with your query, API token, and knowledge base ID, and use the returned chunks as context in your LangChain pipeline. This pattern aligns with how LangChain expects external retrievers to work, and RAGFlow’s API is designed for this use case (SDK example, API details, FAQ). All API usage is self-hosted, so you’ll need to deploy your own RAGFlow instance. There’s no nonstandard integration pattern—just use standard HTTP or Python client calls to retrieve context.
