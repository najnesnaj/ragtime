\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\newlabel{index::doc}{{}{1}{}{section*.2}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}About RAGFlow: Named Among GitHub’s Fastest\sphinxhyphen {}Growing Open Source Projects}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{about:about-ragflow-named-among-githubs-fastest-growing-open-source-projects}{{1}{1}{About RAGFlow: Named Among GitHub’s Fastest\sphinxhyphen {}Growing Open Source Projects}{chapter.1}{}}
\newlabel{about:about-ragflow-octoverse}{{1}{1}{About RAGFlow: Named Among GitHub’s Fastest\sphinxhyphen {}Growing Open Source Projects}{chapter.1}{}}
\newlabel{about::doc}{{1}{1}{About RAGFlow: Named Among GitHub’s Fastest\sphinxhyphen {}Growing Open Source Projects}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}The Rise of Retrieval\sphinxhyphen {}Augmented Generation in Production}{1}{section.1.1}\protected@file@percent }
\newlabel{about:the-rise-of-retrieval-augmented-generation-in-production}{{1.1}{1}{The Rise of Retrieval\sphinxhyphen {}Augmented Generation in Production}{section.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Why RAGFlow Resonates in the AI Era}{1}{section.1.2}\protected@file@percent }
\newlabel{about:why-ragflow-resonates-in-the-ai-era}{{1.2}{1}{Why RAGFlow Resonates in the AI Era}{section.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}A Project in Active Development}{2}{section.1.3}\protected@file@percent }
\newlabel{about:a-project-in-active-development}{{1.3}{2}{A Project in Active Development}{section.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Conclusion}{2}{section.1.4}\protected@file@percent }
\newlabel{about:conclusion}{{1.4}{2}{Conclusion}{section.1.4}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Why Infiniflow RAGFlow Uses a Reranker, an Embedding Model, and a Chat Model}{3}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{rerank:why-infiniflow-ragflow-uses-a-reranker-an-embedding-model-and-a-chat-model}{{2}{3}{Why Infiniflow RAGFlow Uses a Reranker, an Embedding Model, and a Chat Model}{chapter.2}{}}
\newlabel{rerank:ragflow-models}{{2}{3}{Why Infiniflow RAGFlow Uses a Reranker, an Embedding Model, and a Chat Model}{chapter.2}{}}
\newlabel{rerank::doc}{{2}{3}{Why Infiniflow RAGFlow Uses a Reranker, an Embedding Model, and a Chat Model}{chapter.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \sphinxstylestrong {Figure 1}: The reranker evaluates query\sphinxhyphen {}chunk pairs to produce fine\sphinxhyphen {}grained relevance scores.}}{3}{figure.2.1}\protected@file@percent }
\newlabel{rerank:id1}{{1}{3}{\sphinxstylestrong {Figure 1}: The reranker evaluates query\sphinxhyphen {}chunk pairs to produce fine\sphinxhyphen {}grained relevance scores}{figure.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Synergy of the Three Models}{4}{section.2.1}\protected@file@percent }
\newlabel{rerank:synergy-of-the-three-models}{{2.1}{4}{Synergy of the Three Models}{section.2.1}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Why vLLM is Used to Serve the Reranker Model}{5}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{vllm:why-vllm-is-used-to-serve-the-reranker-model}{{3}{5}{Why vLLM is Used to Serve the Reranker Model}{chapter.3}{}}
\newlabel{vllm:vllm-reranker}{{3}{5}{Why vLLM is Used to Serve the Reranker Model}{chapter.3}{}}
\newlabel{vllm::doc}{{3}{5}{Why vLLM is Used to Serve the Reranker Model}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Key Reasons for Using vLLM to Serve the Reranker}{5}{section.3.1}\protected@file@percent }
\newlabel{vllm:key-reasons-for-using-vllm-to-serve-the-reranker}{{3.1}{5}{Key Reasons for Using vLLM to Serve the Reranker}{section.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Serving the Reranker Locally with vLLM}{6}{section.3.2}\protected@file@percent }
\newlabel{vllm:serving-the-reranker-locally-with-vllm}{{3.2}{6}{Serving the Reranker Locally with vLLM}{section.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}RAGFlow Integration}{7}{section.3.3}\protected@file@percent }
\newlabel{vllm:ragflow-integration}{{3.3}{7}{RAGFlow Integration}{section.3.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Serving vLLM Reranker Using Docker (CPU\sphinxhyphen {}Only)}{9}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{vllm-cpu:serving-vllm-reranker-using-docker-cpu-only}{{4}{9}{Serving vLLM Reranker Using Docker (CPU\sphinxhyphen {}Only)}{chapter.4}{}}
\newlabel{vllm-cpu:vllm-docker}{{4}{9}{Serving vLLM Reranker Using Docker (CPU\sphinxhyphen {}Only)}{chapter.4}{}}
\newlabel{vllm-cpu::doc}{{4}{9}{Serving vLLM Reranker Using Docker (CPU\sphinxhyphen {}Only)}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Docker Compose Configuration (CPU Mode)}{9}{section.4.1}\protected@file@percent }
\newlabel{vllm-cpu:docker-compose-configuration-cpu-mode}{{4.1}{9}{Docker Compose Configuration (CPU Mode)}{section.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Key Components Explained}{10}{section.4.2}\protected@file@percent }
\newlabel{vllm-cpu:key-components-explained}{{4.2}{10}{Key Components Explained}{section.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Why the Model Must Be Pre\sphinxhyphen {}Downloaded Locally}{10}{section.4.3}\protected@file@percent }
\newlabel{vllm-cpu:why-the-model-must-be-pre-downloaded-locally}{{4.3}{10}{Why the Model Must Be Pre\sphinxhyphen {}Downloaded Locally}{section.4.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Why CPU\sphinxhyphen {}Only (No GPU)?}{11}{section.4.4}\protected@file@percent }
\newlabel{vllm-cpu:why-cpu-only-no-gpu}{{4.4}{11}{Why CPU\sphinxhyphen {}Only (No GPU)?}{section.4.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Start the Service}{11}{section.4.5}\protected@file@percent }
\newlabel{vllm-cpu:start-the-service}{{4.5}{11}{Start the Service}{section.4.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Verify Availability}{11}{section.4.6}\protected@file@percent }
\newlabel{vllm-cpu:verify-availability}{{4.6}{11}{Verify Availability}{section.4.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Integration with RAGFlow}{11}{section.4.7}\protected@file@percent }
\newlabel{vllm-cpu:integration-with-ragflow}{{4.7}{11}{Integration with RAGFlow}{section.4.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.8}Benefits of This CPU + Docker Setup}{11}{section.4.8}\protected@file@percent }
\newlabel{vllm-cpu:benefits-of-this-cpu-docker-setup}{{4.8}{11}{Benefits of This CPU + Docker Setup}{section.4.8}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Integrating vLLM with RAGFlow via Docker Network}{13}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{vllm-network:integrating-vllm-with-ragflow-via-docker-network}{{5}{13}{Integrating vLLM with RAGFlow via Docker Network}{chapter.5}{}}
\newlabel{vllm-network:ragflow-vllm-network}{{5}{13}{Integrating vLLM with RAGFlow via Docker Network}{chapter.5}{}}
\newlabel{vllm-network::doc}{{5}{13}{Integrating vLLM with RAGFlow via Docker Network}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Why Network Configuration is Required}{13}{section.5.1}\protected@file@percent }
\newlabel{vllm-network:why-network-configuration-is-required}{{5.1}{13}{Why Network Configuration is Required}{section.5.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Step\sphinxhyphen {}by\sphinxhyphen {}Step: Configure Docker Network}{13}{section.5.2}\protected@file@percent }
\newlabel{vllm-network:step-by-step-configure-docker-network}{{5.2}{13}{Step\sphinxhyphen {}by\sphinxhyphen {}Step: Configure Docker Network}{section.5.2}{}}
\@writefile{lol}{\contentsline {literalblock}{\numberline {1}{\ignorespaces docker\sphinxhyphen {}compose.yaml (vLLM)}}{13}{literalblock.5.1}\protected@file@percent }
\newlabel{vllm-network:id1}{{1}{13}{\sphinxLiteralBlockLabel docker\sphinxhyphen {}compose.yaml (vLLM)}{literalblock.5.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Architecture Diagram}{15}{section.5.3}\protected@file@percent }
\newlabel{vllm-network:architecture-diagram}{{5.3}{15}{Architecture Diagram}{section.5.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Verification}{15}{section.5.4}\protected@file@percent }
\newlabel{vllm-network:verification}{{5.4}{15}{Verification}{section.5.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Benefits of This Setup}{15}{section.5.5}\protected@file@percent }
\newlabel{vllm-network:benefits-of-this-setup}{{5.5}{15}{Benefits of This Setup}{section.5.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Troubleshooting Tips}{15}{section.5.6}\protected@file@percent }
\newlabel{vllm-network:troubleshooting-tips}{{5.6}{15}{Troubleshooting Tips}{section.5.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \sphinxstylestrong {Figure 1}: RAGFlow containers communicate with vLLM reranker via internal Docker network \sphinxtitleref {docker\sphinxhyphen {}ragflow}. External access (optional) via port \sphinxtitleref {8123}.}}{16}{figure.5.1}\protected@file@percent }
\newlabel{vllm-network:id2}{{1}{16}{\sphinxstylestrong {Figure 1}: RAGFlow containers communicate with vLLM reranker via internal Docker network \sphinxtitleref {docker\sphinxhyphen {}ragflow}. External access (optional) via port \sphinxtitleref {8123}}{figure.5.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.7}Summary}{17}{section.5.7}\protected@file@percent }
\newlabel{vllm-network:summary}{{5.7}{17}{Summary}{section.5.7}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Batch Processing and Metadata Management in Infiniflow RAGFlow}{19}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{api:batch-processing-and-metadata-management-in-infiniflow-ragflow}{{6}{19}{Batch Processing and Metadata Management in Infiniflow RAGFlow}{chapter.6}{}}
\newlabel{api:ragflow-batch-api}{{6}{19}{Batch Processing and Metadata Management in Infiniflow RAGFlow}{chapter.6}{}}
\newlabel{api::doc}{{6}{19}{Batch Processing and Metadata Management in Infiniflow RAGFlow}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}API Base URL}{19}{section.6.1}\protected@file@percent }
\newlabel{api:api-base-url}{{6.1}{19}{API Base URL}{section.6.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Authentication}{19}{section.6.2}\protected@file@percent }
\newlabel{api:authentication}{{6.2}{19}{Authentication}{section.6.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Step 1: Retrieve Dataset and Document IDs}{20}{section.6.3}\protected@file@percent }
\newlabel{api:step-1-retrieve-dataset-and-document-ids}{{6.3}{20}{Step 1: Retrieve Dataset and Document IDs}{section.6.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Step 2: Add Metadata to a Document (via PUT)}{20}{section.6.4}\protected@file@percent }
\newlabel{api:step-2-add-metadata-to-a-document-via-put}{{6.4}{20}{Step 2: Add Metadata to a Document (via PUT)}{section.6.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Use Case: Batch Metadata Enrichment}{21}{section.6.5}\protected@file@percent }
\newlabel{api:use-case-batch-metadata-enrichment}{{6.5}{21}{Use Case: Batch Metadata Enrichment}{section.6.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Other Batch\sphinxhyphen {}Capable Endpoints}{22}{section.6.6}\protected@file@percent }
\newlabel{api:other-batch-capable-endpoints}{{6.6}{22}{Other Batch\sphinxhyphen {}Capable Endpoints}{section.6.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.7}Best Practices}{22}{section.6.7}\protected@file@percent }
\newlabel{api:best-practices}{{6.7}{22}{Best Practices}{section.6.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.8}Summary}{22}{section.6.8}\protected@file@percent }
\newlabel{api:summary}{{6.8}{22}{Summary}{section.6.8}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}How the Knowledge Graph in Infiniflow/RAGFlow Works}{23}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{graph:how-the-knowledge-graph-in-infiniflow-ragflow-works}{{7}{23}{How the Knowledge Graph in Infiniflow/RAGFlow Works}{chapter.7}{}}
\newlabel{graph::doc}{{7}{23}{How the Knowledge Graph in Infiniflow/RAGFlow Works}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Overview}{23}{section.7.1}\protected@file@percent }
\newlabel{graph:overview}{{7.1}{23}{Overview}{section.7.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Construction Process}{23}{section.7.2}\protected@file@percent }
\newlabel{graph:construction-process}{{7.2}{23}{Construction Process}{section.7.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Query and Retrieval Process}{24}{section.7.3}\protected@file@percent }
\newlabel{graph:query-and-retrieval-process}{{7.3}{24}{Query and Retrieval Process}{section.7.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.4}Key Features and Limitations}{24}{section.7.4}\protected@file@percent }
\newlabel{graph:key-features-and-limitations}{{7.4}{24}{Key Features and Limitations}{section.7.4}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Running Llama 3.1 with llama.cpp}{25}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{llama-cpp:running-llama-3-1-with-llama-cpp}{{8}{25}{Running Llama 3.1 with llama.cpp}{chapter.8}{}}
\newlabel{llama-cpp:llama-cpp-model-format-gguf}{{8}{25}{Running Llama 3.1 with llama.cpp}{chapter.8}{}}
\newlabel{llama-cpp::doc}{{8}{25}{Running Llama 3.1 with llama.cpp}{chapter.8}{}}
\newlabel{llama-cpp:id1}{{8}{25}{Running Llama 3.1 with llama.cpp}{section*.3}{}}
\newlabel{llama-cpp:id2}{{8}{25}{Running Llama 3.1 with llama.cpp}{section*.4}{}}
\newlabel{llama-cpp:id3}{{8}{25}{Running Llama 3.1 with llama.cpp}{section*.5}{}}
\newlabel{llama-cpp:id4}{{8}{25}{Running Llama 3.1 with llama.cpp}{section*.6}{}}
\newlabel{llama-cpp:id5}{{8}{25}{Running Llama 3.1 with llama.cpp}{section*.7}{}}
\newlabel{llama-cpp:id6}{{8}{25}{Running Llama 3.1 with llama.cpp}{section*.8}{}}
\newlabel{llama-cpp:id7}{{8}{25}{Running Llama 3.1 with llama.cpp}{section*.9}{}}
\newlabel{llama-cpp:id8}{{8}{25}{Running Llama 3.1 with llama.cpp}{section*.10}{}}
\newlabel{llama-cpp:id9}{{8}{25}{Running Llama 3.1 with llama.cpp}{section*.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}1. Model Format: GGUF}{25}{section.8.1}\protected@file@percent }
\newlabel{llama-cpp:model-format-gguf}{{8.1}{25}{1. Model Format: GGUF}{section.8.1}{}}
\newlabel{llama-cpp:llama-cpp-compile-llama-cpp-for-intel-i7-cpu-only}{{8.1}{25}{1. Model Format: GGUF}{section.8.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}2. Compile llama.cpp for Intel i7 (CPU\sphinxhyphen {}only)}{26}{section.8.2}\protected@file@percent }
\newlabel{llama-cpp:compile-llama-cpp-for-intel-i7-cpu-only}{{8.2}{26}{2. Compile llama.cpp for Intel i7 (CPU\sphinxhyphen {}only)}{section.8.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.3}3. Run the Model with Web Interface}{26}{section.8.3}\protected@file@percent }
\newlabel{llama-cpp:run-the-model-with-web-interface}{{8.3}{26}{3. Run the Model with Web Interface}{section.8.3}{}}
\newlabel{llama-cpp:llama-cpp-run-the-model-with-web-interface}{{8.3}{26}{3. Run the Model with Web Interface}{section.8.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3.1}Features}{26}{subsection.8.3.1}\protected@file@percent }
\newlabel{llama-cpp:features}{{8.3.1}{26}{Features}{subsection.8.3.1}{}}
\newlabel{llama-cpp:llama-cpp-features}{{8.3.1}{26}{Features}{subsection.8.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.4}4. Compile llama.cpp with NVIDIA GPU Support (CUDA)}{27}{section.8.4}\protected@file@percent }
\newlabel{llama-cpp:compile-llama-cpp-with-nvidia-gpu-support-cuda}{{8.4}{27}{4. Compile llama.cpp with NVIDIA GPU Support (CUDA)}{section.8.4}{}}
\newlabel{llama-cpp:llama-cpp-compile-llama-cpp-with-nvidia-gpu-support-cuda}{{8.4}{27}{4. Compile llama.cpp with NVIDIA GPU Support (CUDA)}{section.8.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4.1}Prerequisites}{27}{subsection.8.4.1}\protected@file@percent }
\newlabel{llama-cpp:prerequisites}{{8.4.1}{27}{Prerequisites}{subsection.8.4.1}{}}
\newlabel{llama-cpp:llama-cpp-prerequisites}{{8.4.1}{27}{Prerequisites}{subsection.8.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4.2}Build with CUDA}{27}{subsection.8.4.2}\protected@file@percent }
\newlabel{llama-cpp:build-with-cuda}{{8.4.2}{27}{Build with CUDA}{subsection.8.4.2}{}}
\newlabel{llama-cpp:llama-cpp-build-with-cuda}{{8.4.2}{27}{Build with CUDA}{subsection.8.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4.3}Run with GPU offloading}{28}{subsection.8.4.3}\protected@file@percent }
\newlabel{llama-cpp:run-with-gpu-offloading}{{8.4.3}{28}{Run with GPU offloading}{subsection.8.4.3}{}}
\newlabel{llama-cpp:llama-cpp-run-with-gpu-offloading}{{8.4.3}{28}{Run with GPU offloading}{subsection.8.4.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.5}Summary}{28}{section.8.5}\protected@file@percent }
\newlabel{llama-cpp:summary}{{8.5}{28}{Summary}{section.8.5}{}}
\newlabel{llama-cpp:llama-cpp-summary}{{8.5}{28}{Summary}{section.8.5}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Deploying LLMs in Hybrid Cloud: Why llama.cpp Wins for Us}{29}{chapter.9}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{hybrid:deploying-llms-in-hybrid-cloud-why-llama-cpp-wins-for-us}{{9}{29}{Deploying LLMs in Hybrid Cloud: Why llama.cpp Wins for Us}{chapter.9}{}}
\newlabel{hybrid::doc}{{9}{29}{Deploying LLMs in Hybrid Cloud: Why llama.cpp Wins for Us}{chapter.9}{}}
\newlabel{hybrid:id5}{{9}{29}{Deploying LLMs in Hybrid Cloud: Why llama.cpp Wins for Us}{section*.12}{}}
\newlabel{hybrid:id6}{{9}{29}{Deploying LLMs in Hybrid Cloud: Why llama.cpp Wins for Us}{section*.13}{}}
\newlabel{hybrid:id7}{{9}{29}{Deploying LLMs in Hybrid Cloud: Why llama.cpp Wins for Us}{section*.14}{}}
\newlabel{hybrid:id8}{{9}{29}{Deploying LLMs in Hybrid Cloud: Why llama.cpp Wins for Us}{section*.15}{}}
\newlabel{hybrid:id9}{{9}{29}{Deploying LLMs in Hybrid Cloud: Why llama.cpp Wins for Us}{section*.16}{}}
\newlabel{hybrid:id10}{{9}{29}{Deploying LLMs in Hybrid Cloud: Why llama.cpp Wins for Us}{section*.17}{}}
\newlabel{hybrid:id11}{{9}{29}{Deploying LLMs in Hybrid Cloud: Why llama.cpp Wins for Us}{section*.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}1. Current Setup: Ollama in Testing}{29}{section.9.1}\protected@file@percent }
\newlabel{hybrid:current-setup-ollama-in-testing}{{9.1}{29}{1. Current Setup: Ollama in Testing}{section.9.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.2}2. Production Requirements: Hybrid Cloud \& Multi\sphinxhyphen {}User Access}{30}{section.9.2}\protected@file@percent }
\newlabel{hybrid:production-requirements-hybrid-cloud-multi-user-access}{{9.2}{30}{2. Production Requirements: Hybrid Cloud \& Multi\sphinxhyphen {}User Access}{section.9.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.3}3. Evaluation: vLLM vs llama.cpp}{30}{section.9.3}\protected@file@percent }
\newlabel{hybrid:evaluation-vllm-vs-llama-cpp}{{9.3}{30}{3. Evaluation: vLLM vs llama.cpp}{section.9.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.4}4. Why llama.cpp Is Our Production Choice}{30}{section.9.4}\protected@file@percent }
\newlabel{hybrid:why-llama-cpp-is-our-production-choice}{{9.4}{30}{4. Why llama.cpp Is Our Production Choice}{section.9.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.1}Example: Production\sphinxhyphen {}Ready Server}{31}{subsection.9.4.1}\protected@file@percent }
\newlabel{hybrid:example-production-ready-server}{{9.4.1}{31}{Example: Production\sphinxhyphen {}Ready Server}{subsection.9.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.5}5. Migration Path: From Ollama \(\rightarrow \) llama.cpp}{31}{section.9.5}\protected@file@percent }
\newlabel{hybrid:migration-path-from-ollama-llama-cpp}{{9.5}{31}{5. Migration Path: From Ollama \(\rightarrow \) llama.cpp}{section.9.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.6}Summary}{31}{section.9.6}\protected@file@percent }
\newlabel{hybrid:summary}{{9.6}{31}{Summary}{section.9.6}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Indices and tables}{33}{chapter.10}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{index:indices-and-tables}{{10}{33}{Indices and tables}{chapter.10}{}}
\gdef \@abspage@last{37}
