\babel@toc {english}{}\relax 
\contentsline {chapter}{\numberline {1}About RAGFlow: Named Among GitHubâ€™s Fastest\sphinxhyphen {}Growing Open Source Projects}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}The Rise of Retrieval\sphinxhyphen {}Augmented Generation in Production}{1}{section.1.1}%
\contentsline {section}{\numberline {1.2}Why RAGFlow Resonates in the AI Era}{1}{section.1.2}%
\contentsline {section}{\numberline {1.3}A Project in Active Development}{2}{section.1.3}%
\contentsline {section}{\numberline {1.4}Conclusion}{2}{section.1.4}%
\contentsline {chapter}{\numberline {2}Why Infiniflow RAGFlow Uses a Reranker, an Embedding Model, and a Chat Model}{3}{chapter.2}%
\contentsline {section}{\numberline {2.1}Synergy of the Three Models}{4}{section.2.1}%
\contentsline {chapter}{\numberline {3}Why vLLM is Used to Serve the Reranker Model}{5}{chapter.3}%
\contentsline {section}{\numberline {3.1}Key Reasons for Using vLLM to Serve the Reranker}{5}{section.3.1}%
\contentsline {section}{\numberline {3.2}Serving the Reranker Locally with vLLM}{6}{section.3.2}%
\contentsline {section}{\numberline {3.3}RAGFlow Integration}{7}{section.3.3}%
\contentsline {chapter}{\numberline {4}Serving vLLM Reranker Using Docker (CPU\sphinxhyphen {}Only)}{9}{chapter.4}%
\contentsline {section}{\numberline {4.1}Docker Compose Configuration (CPU Mode)}{9}{section.4.1}%
\contentsline {section}{\numberline {4.2}Key Components Explained}{10}{section.4.2}%
\contentsline {section}{\numberline {4.3}Why the Model Must Be Pre\sphinxhyphen {}Downloaded Locally}{10}{section.4.3}%
\contentsline {section}{\numberline {4.4}Why CPU\sphinxhyphen {}Only (No GPU)?}{11}{section.4.4}%
\contentsline {section}{\numberline {4.5}Start the Service}{11}{section.4.5}%
\contentsline {section}{\numberline {4.6}Verify Availability}{11}{section.4.6}%
\contentsline {section}{\numberline {4.7}Integration with RAGFlow}{11}{section.4.7}%
\contentsline {section}{\numberline {4.8}Benefits of This CPU + Docker Setup}{11}{section.4.8}%
\contentsline {chapter}{\numberline {5}Integrating vLLM with RAGFlow via Docker Network}{13}{chapter.5}%
\contentsline {section}{\numberline {5.1}Why Network Configuration is Required}{13}{section.5.1}%
\contentsline {section}{\numberline {5.2}Step\sphinxhyphen {}by\sphinxhyphen {}Step: Configure Docker Network}{13}{section.5.2}%
\contentsline {section}{\numberline {5.3}Architecture Diagram}{15}{section.5.3}%
\contentsline {section}{\numberline {5.4}Verification}{15}{section.5.4}%
\contentsline {section}{\numberline {5.5}Benefits of This Setup}{15}{section.5.5}%
\contentsline {section}{\numberline {5.6}Troubleshooting Tips}{15}{section.5.6}%
\contentsline {section}{\numberline {5.7}Summary}{17}{section.5.7}%
\contentsline {chapter}{\numberline {6}Batch Processing and Metadata Management in Infiniflow RAGFlow}{19}{chapter.6}%
\contentsline {section}{\numberline {6.1}API Base URL}{19}{section.6.1}%
\contentsline {section}{\numberline {6.2}Authentication}{19}{section.6.2}%
\contentsline {section}{\numberline {6.3}Step 1: Retrieve Dataset and Document IDs}{20}{section.6.3}%
\contentsline {section}{\numberline {6.4}Step 2: Add Metadata to a Document (via PUT)}{20}{section.6.4}%
\contentsline {section}{\numberline {6.5}Use Case: Batch Metadata Enrichment}{21}{section.6.5}%
\contentsline {section}{\numberline {6.6}Other Batch\sphinxhyphen {}Capable Endpoints}{22}{section.6.6}%
\contentsline {section}{\numberline {6.7}Best Practices}{22}{section.6.7}%
\contentsline {section}{\numberline {6.8}Summary}{22}{section.6.8}%
\contentsline {chapter}{\numberline {7}How the Knowledge Graph in Infiniflow/RAGFlow Works}{23}{chapter.7}%
\contentsline {section}{\numberline {7.1}Overview}{23}{section.7.1}%
\contentsline {section}{\numberline {7.2}Construction Process}{23}{section.7.2}%
\contentsline {section}{\numberline {7.3}Query and Retrieval Process}{24}{section.7.3}%
\contentsline {section}{\numberline {7.4}Key Features and Limitations}{24}{section.7.4}%
\contentsline {chapter}{\numberline {8}Indices and tables}{25}{chapter.8}%
