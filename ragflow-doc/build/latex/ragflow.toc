\babel@toc {english}{}\relax 
\contentsline {chapter}{\numberline {1}About RAGFlow: Named Among GitHub’s Fastest\sphinxhyphen {}Growing Open Source Projects}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}The Rise of Retrieval\sphinxhyphen {}Augmented Generation in Production}{1}{section.1.1}%
\contentsline {section}{\numberline {1.2}Why RAGFlow Resonates in the AI Era}{1}{section.1.2}%
\contentsline {section}{\numberline {1.3}A Project in Active Development}{2}{section.1.3}%
\contentsline {section}{\numberline {1.4}Conclusion}{2}{section.1.4}%
\contentsline {chapter}{\numberline {2}Security Concerns}{3}{chapter.2}%
\contentsline {section}{\numberline {2.1}considerations:}{3}{section.2.1}%
\contentsline {section}{\numberline {2.2}sandbox:}{3}{section.2.2}%
\contentsline {section}{\numberline {2.3}elasticsearch:}{4}{section.2.3}%
\contentsline {chapter}{\numberline {3}RAGFlow System Architecture}{5}{chapter.3}%
\contentsline {section}{\numberline {3.1}Overview}{5}{section.3.1}%
\contentsline {section}{\numberline {3.2}Core Infrastructure Containers}{5}{section.3.2}%
\contentsline {section}{\numberline {3.3}RAGFlow Application Containers}{5}{section.3.3}%
\contentsline {section}{\numberline {3.4}High\sphinxhyphen {}Level Architecture Diagram}{6}{section.3.4}%
\contentsline {section}{\numberline {3.5}Data \& Execution Flow}{6}{section.3.5}%
\contentsline {chapter}{\numberline {4}From RAG to Context \sphinxhyphen {} A 2025 Year\sphinxhyphen {}End Review of RAG}{7}{chapter.4}%
\contentsline {section}{\numberline {4.1}Can RAG Still Be Improved?}{7}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}The Debate About Long Context and RAG}{7}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}Optimizations for RAG Conversational Quality}{8}{subsection.4.1.2}%
\contentsline {subsection}{\numberline {4.1.3}From Knowledge Base to Data Foundation}{9}{subsection.4.1.3}%
\contentsline {chapter}{\numberline {5}example:}{11}{chapter.5}%
\contentsline {section}{\numberline {5.1}Why Infiniflow RAGFlow Uses a Reranker, an Embedding Model, and a Chat Model}{11}{section.5.1}%
\contentsline {chapter}{\numberline {6}Synergy of the Three Models}{13}{chapter.6}%
\contentsline {chapter}{\numberline {7}Why vLLM is Used to Serve the Reranker Model}{15}{chapter.7}%
\contentsline {section}{\numberline {7.1}Key Reasons for Using vLLM to Serve the Reranker}{15}{section.7.1}%
\contentsline {section}{\numberline {7.2}Serving the Reranker Locally with vLLM}{16}{section.7.2}%
\contentsline {section}{\numberline {7.3}RAGFlow Integration}{17}{section.7.3}%
\contentsline {chapter}{\numberline {8}Serving vLLM Reranker Using Docker (CPU\sphinxhyphen {}Only)}{19}{chapter.8}%
\contentsline {section}{\numberline {8.1}Docker Compose Configuration (CPU Mode)}{19}{section.8.1}%
\contentsline {section}{\numberline {8.2}Key Components Explained}{20}{section.8.2}%
\contentsline {section}{\numberline {8.3}Why the Model Must Be Pre\sphinxhyphen {}Downloaded Locally}{20}{section.8.3}%
\contentsline {section}{\numberline {8.4}Why CPU\sphinxhyphen {}Only (No GPU)?}{21}{section.8.4}%
\contentsline {section}{\numberline {8.5}Start the Service}{21}{section.8.5}%
\contentsline {section}{\numberline {8.6}Verify Availability}{21}{section.8.6}%
\contentsline {section}{\numberline {8.7}Integration with RAGFlow}{21}{section.8.7}%
\contentsline {section}{\numberline {8.8}Benefits of This CPU + Docker Setup}{21}{section.8.8}%
\contentsline {chapter}{\numberline {9}Integrating vLLM with RAGFlow via Docker Network}{23}{chapter.9}%
\contentsline {section}{\numberline {9.1}Why Network Configuration is Required}{23}{section.9.1}%
\contentsline {section}{\numberline {9.2}Step\sphinxhyphen {}by\sphinxhyphen {}Step: Configure Docker Network}{23}{section.9.2}%
\contentsline {section}{\numberline {9.3}Architecture Diagram}{25}{section.9.3}%
\contentsline {section}{\numberline {9.4}Verification}{25}{section.9.4}%
\contentsline {section}{\numberline {9.5}Benefits of This Setup}{25}{section.9.5}%
\contentsline {section}{\numberline {9.6}Troubleshooting Tips}{25}{section.9.6}%
\contentsline {section}{\numberline {9.7}Summary}{27}{section.9.7}%
\contentsline {chapter}{\numberline {10}Batch Processing and Metadata Management in Infiniflow RAGFlow}{29}{chapter.10}%
\contentsline {section}{\numberline {10.1}API Base URL}{29}{section.10.1}%
\contentsline {section}{\numberline {10.2}Authentication}{29}{section.10.2}%
\contentsline {section}{\numberline {10.3}Step 1: Retrieve Dataset and Document IDs}{30}{section.10.3}%
\contentsline {section}{\numberline {10.4}Step 2: Add Metadata to a Document (via PUT)}{30}{section.10.4}%
\contentsline {section}{\numberline {10.5}Use Case: Batch Metadata Enrichment}{31}{section.10.5}%
\contentsline {section}{\numberline {10.6}Other Batch\sphinxhyphen {}Capable Endpoints}{32}{section.10.6}%
\contentsline {section}{\numberline {10.7}Best Practices}{32}{section.10.7}%
\contentsline {section}{\numberline {10.8}See also:}{32}{section.10.8}%
\contentsline {section}{\numberline {10.9}Summary}{32}{section.10.9}%
\contentsline {chapter}{\numberline {11}How the Knowledge Graph in Infiniflow/RAGFlow Works}{33}{chapter.11}%
\contentsline {section}{\numberline {11.1}Overview}{33}{section.11.1}%
\contentsline {section}{\numberline {11.2}Construction Process}{33}{section.11.2}%
\contentsline {section}{\numberline {11.3}Query and Retrieval Process}{34}{section.11.3}%
\contentsline {section}{\numberline {11.4}Key Features and Limitations}{34}{section.11.4}%
\contentsline {chapter}{\numberline {12}Running Llama 3.1 with llama.cpp}{35}{chapter.12}%
\contentsline {section}{\numberline {12.1}1. Model Format: GGUF}{35}{section.12.1}%
\contentsline {section}{\numberline {12.2}2. Compile llama.cpp for Intel i7 (CPU\sphinxhyphen {}only)}{36}{section.12.2}%
\contentsline {section}{\numberline {12.3}3. Run the Model with Web Interface}{36}{section.12.3}%
\contentsline {subsection}{\numberline {12.3.1}Features}{37}{subsection.12.3.1}%
\contentsline {section}{\numberline {12.4}4. Compile llama.cpp with NVIDIA GPU Support (CUDA)}{37}{section.12.4}%
\contentsline {subsection}{\numberline {12.4.1}Prerequisites}{37}{subsection.12.4.1}%
\contentsline {subsection}{\numberline {12.4.2}Build with CUDA}{38}{subsection.12.4.2}%
\contentsline {subsection}{\numberline {12.4.3}Run with GPU offloading}{38}{subsection.12.4.3}%
\contentsline {section}{\numberline {12.5}Summary}{38}{section.12.5}%
\contentsline {chapter}{\numberline {13}Running Multiple Models on llama.cpp Using Docker}{39}{chapter.13}%
\contentsline {section}{\numberline {13.1}Example \sphinxstyleliteralintitle {\sphinxupquote {docker\sphinxhyphen {}compose.yml}}}{39}{section.13.1}%
\contentsline {section}{\numberline {13.2}Key Configuration Notes}{40}{section.13.2}%
\contentsline {section}{\numberline {13.3}Usage}{40}{section.13.3}%
\contentsline {chapter}{\numberline {14}Deploying LLMs in Hybrid Cloud: Why llama.cpp Wins for Us}{41}{chapter.14}%
\contentsline {section}{\numberline {14.1}1. Current Setup: Ollama in Testing}{41}{section.14.1}%
\contentsline {section}{\numberline {14.2}2. Production Requirements: Hybrid Cloud \& Multi\sphinxhyphen {}User Access}{42}{section.14.2}%
\contentsline {section}{\numberline {14.3}3. Evaluation: vLLM vs llama.cpp}{42}{section.14.3}%
\contentsline {section}{\numberline {14.4}4. Why llama.cpp Is Our Production Choice}{42}{section.14.4}%
\contentsline {subsection}{\numberline {14.4.1}Example: Production\sphinxhyphen {}Ready Server}{43}{subsection.14.4.1}%
\contentsline {section}{\numberline {14.5}5. Migration Path: From Ollama \(\rightarrow \) llama.cpp}{43}{section.14.5}%
\contentsline {section}{\numberline {14.6}Summary}{43}{section.14.6}%
\contentsline {chapter}{\numberline {15}How InfiniFlow RAGFlow Uses gVisor}{45}{chapter.15}%
\contentsline {section}{\numberline {15.1}gVisor Integration}{45}{section.15.1}%
\contentsline {subsection}{\numberline {15.1.1}What is gVisor?}{45}{subsection.15.1.1}%
\contentsline {section}{\numberline {15.2}How RAGFlow Uses gVisor Sandboxes}{45}{section.15.2}%
\contentsline {section}{\numberline {15.3}Security Advantages in Practice}{46}{section.15.3}%
\contentsline {section}{\numberline {15.4}Enabling/Disabling the Sandbox}{46}{section.15.4}%
\contentsline {section}{\numberline {15.5}Summary}{46}{section.15.5}%
\contentsline {chapter}{\numberline {16}RAGFlow GPU vs CPU: Full Explanation (2025 Edition)}{47}{chapter.16}%
\contentsline {section}{\numberline {16.1}Why Does RAGFlow Still Need a GPU Even When Using Ollama?}{47}{section.16.1}%
\contentsline {section}{\numberline {16.2}Complete RAGFlow Pipeline (with GPU usage marked)}{47}{section.16.2}%
\contentsline {section}{\numberline {16.3}What DeepDoc Actually Does (and Why GPU Makes It 5\textendash {}20× Faster)}{48}{section.16.3}%
\contentsline {section}{\numberline {16.4}Real\sphinxhyphen {}World Performance Numbers}{48}{section.16.4}%
\contentsline {section}{\numberline {16.5}When Do You Actually Need ragflow\sphinxhyphen {}gpu?}{48}{section.16.5}%
\contentsline {section}{\numberline {16.6}Recommended Setup in 2025 (Best of Both Worlds)}{48}{section.16.6}%
\contentsline {section}{\numberline {16.7}Monitoring \& Verification}{49}{section.16.7}%
\contentsline {section}{\numberline {16.8}Conclusion}{49}{section.16.8}%
\contentsline {chapter}{\numberline {17}Upgrade to latest release :}{51}{chapter.17}%
\contentsline {chapter}{\numberline {18}upload document}{53}{chapter.18}%
\contentsline {section}{\numberline {18.1}response}{53}{section.18.1}%
\contentsline {chapter}{\numberline {19}Graphrag}{55}{chapter.19}%
\contentsline {section}{\numberline {19.1}reponse (json)}{55}{section.19.1}%
\contentsline {section}{\numberline {19.2}graphrag}{55}{section.19.2}%
\contentsline {subsection}{\numberline {19.2.1}{[}GIN{]} 2025/11/25 \sphinxhyphen {} 10:15:40 | 200 | 5m44s | 172.17.0.1 | POST “/api/chat”}{56}{subsection.19.2.1}%
\contentsline {section}{\numberline {19.3}So slow, need to see progress}{56}{section.19.3}%
\contentsline {section}{\numberline {19.4}Stuck ???? what now????}{57}{section.19.4}%
\contentsline {chapter}{\numberline {20}Chat}{59}{chapter.20}%
\contentsline {chapter}{\numberline {21}Why Infinity is a Good Alternative in RAGFlow}{61}{chapter.21}%
\contentsline {section}{\numberline {21.1}Tailored for RAG/LLM Workloads}{61}{section.21.1}%
\contentsline {section}{\numberline {21.2}Performance \& Efficiency}{61}{section.21.2}%
\contentsline {section}{\numberline {21.3}Integration in RAGFlow}{61}{section.21.3}%
\contentsline {section}{\numberline {21.4}Fully Open Source \& Vendor\sphinxhyphen {}Neutral}{61}{section.21.4}%
\contentsline {section}{\numberline {21.5}Drawbacks}{61}{section.21.5}%
\contentsline {chapter}{\numberline {22}MinerU and Its Use in RAGFlow}{63}{chapter.22}%
\contentsline {section}{\numberline {22.1}Introduction to MinerU}{63}{section.22.1}%
\contentsline {section}{\numberline {22.2}MinerU in RAGFlow}{63}{section.22.2}%
\contentsline {section}{\numberline {22.3}Comparison with Existing PDF Ingestion Tools}{64}{section.22.3}%
\contentsline {section}{\numberline {22.4}Summary of MinerU Advantages}{64}{section.22.4}%
\contentsline {section}{\numberline {22.5}Activating MinerU in RagFlow}{64}{section.22.5}%
\contentsline {chapter}{\numberline {23}What is Agent context engine?}{65}{chapter.23}%
\contentsline {section}{\numberline {23.1}Beyond the hype: The reality of today’s “intelligent” Agents}{65}{section.23.1}%
\contentsline {section}{\numberline {23.2}Deconstructing the Agent Context Engine}{65}{section.23.2}%
\contentsline {section}{\numberline {23.3}Why we need a dedicated engine? The case for a unified substrate}{66}{section.23.3}%
\contentsline {section}{\numberline {23.4}RAGFlow: A resolute march toward the context engine of Agents}{66}{section.23.4}%
\contentsline {chapter}{\numberline {24}Using SearXNG with RAGFlow}{67}{chapter.24}%
\contentsline {section}{\numberline {24.1}Introduction to SearXNG in RAGFlow Agents}{67}{section.24.1}%
\contentsline {section}{\numberline {24.2}Benefits of Using SearXNG with RAGFlow}{67}{section.24.2}%
\contentsline {section}{\numberline {24.3}Benefits for Intranet Page Browsing}{68}{section.24.3}%
\contentsline {section}{\numberline {24.4}Deployment in Docker Containers}{68}{section.24.4}%
\contentsline {subsection}{\numberline {24.4.1}1. Deploy SearXNG}{68}{subsection.24.4.1}%
\contentsline {subsection}{\numberline {24.4.2}2. Integrate with RAGFlow}{68}{subsection.24.4.2}%
\contentsline {subsection}{\numberline {24.4.3}Combined Example Network}{69}{subsection.24.4.3}%
\contentsline {section}{\numberline {24.5}Conclusion}{70}{section.24.5}%
\contentsline {chapter}{\numberline {25}homelab}{71}{chapter.25}%
\contentsline {section}{\numberline {25.1}problem older hardware :}{71}{section.25.1}%
\contentsline {section}{\numberline {25.2}software :}{71}{section.25.2}%
\contentsline {section}{\numberline {25.3}problem reranking:}{71}{section.25.3}%
\contentsline {section}{\numberline {25.4}possible solution:}{71}{section.25.4}%
\contentsline {chapter}{\numberline {26}Indices and tables}{73}{chapter.26}%
